CHANGES MADE:
- Removed Improper Tanh() Activation from CNN, CED, RCED, UNet
    Models previously ended with nn.Tanh(), which clamps real/imag spectrogram outputs to [-1, 1]. Suppressing output and creating poor waveform reconstructions. With Low SNR/PESQ/STOI metrics that where clear anomolies.

    This was first visualized when individual denoised audios where plotted for time-domain waveforms and spectrograms. Where the supressed and unnatural flattened enegery was seen.

    
- Mention that the training pipeline and denoising pipeline use a unified SNR calcualtion.

Wiener Filter Fix Summary
- Original implementation used torch.min() across time to estimate noise PSD, which underestimated the noise and caused unstable or overly strong filtering. I replaced this with a more robust method: taking the mean of the first 6 STFT frames (assumed noise-only) to estimate the noise PSD. Also added a small epsilon to prevent divide-by-zero. Retained exponential smoothing (α = 0.85) on the gain. Result: SNR improved, MSE and PESQ got better, and filtering became more stable and realistic.

Fixing MMSE-LSA Performance Issues
-The initial MMSE-LSA implementation exhibited heavily negative SNR values and visibly over-suppressed waveforms, despite high STOI and PESQ scores. This indicated that while the speech was intelligible, much of the signal energy was being lost, leading to poor numerical quality. To address this, we revised the gain computation by introducing a lower bound (gain floor) of 0.1 to prevent total attenuation of low-energy regions. Additionally, we removed unused parameters (like α), clarified the role of β in smoothing the a priori SNR, and retained a simple yet effective exponential integral approximation. These adjustments significantly reduced over-suppression, restoring signal power and improving SNR without degrading perceptual metrics.

Nature and Trade-offs of MMSE-LSA
-MMSE-LSA is designed to minimize log-spectral distortion by estimating an optimal gain function that suppresses noise while preserving speech. However, in practice, its strong suppression can sometimes eliminate important speech details, especially in low-SNR scenarios, which leads to a trade-off: high PESQ/STOI (perceptual quality and intelligibility) versus low SNR (numerical fidelity). This highlights MMSE-LSA’s inherent bias toward perceptual improvement rather than strict signal preservation. As such, careful gain floor tuning and noise estimation become essential when applying MMSE-LSA to real-world speech enhancement tasks.


Change the appendix section of the project structure to the encapsulated single denoise now.

Move all introduction paraghraphs for chapters to Overiew section in intro

Evaluation
                    - Check the major 18 x of ConvTasNet compared to the other models seems very large and need to make comments on it.
                    - Compare models subjectively off of single test audios
                    - Compare models to a pretrained model
                    - Oringal metrics of nosiy to clean. (especially for SNR) 
                    - Mention that the metrics taken are of whole bacth of the noisy test set and are averges.

Conclusion
                    - We need to conclude on the question of Classical vs ML
                    - State that although we struggled to find significant imporvements in models and one that did perform well. The results blew through any optimistic results of Classical methods.
                    - State ConvTasNet as our best performer good for deployment
                    - Possibly mention deployment 

Consistenty:
                    - British English not American
                    - \texttt fit for coding names 
                    - \textbf titles

Fix the denoising of the classical single methods

Conduct Hyperparmater tuning

Deployment Code

Possible needs for changes:
    -1.1  However, during evaluation and benchmarking, pre-trained models
    will be used for comparison to assess their effectiveness against the proposed
    approach.

    -1.1 The project is structured into three core phases: training, denoising,
    and deployment....

    -2.5 and assess their feasibility for real-time embedded deployment

Questions to ask: