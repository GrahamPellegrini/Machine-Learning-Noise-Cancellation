@book{loizou2013speech,
  author    = {Philipos C. Loizou},
  title     = {Speech Enhancement: Theory and Practice},
  publisher = {CRC Press},
  year      = {2013},
  edition   = {2nd},
  isbn      = {9781466504219}
}

@mastersthesis{dubey2016evaluation,
  title     = {Evaluation of Signal Processing Methods for Speech Enhancement},
  author    = {Dubey, Mahika},
  year      = {2016},
  school    = {University of Illinois at Urbana-Champaign},
  note      = {Advisor: Paris Smaragdis},
  url       = {http://hdl.handle.net/2142/90373}
}

@article{ephraim1984speech,
  title={Speech enhancement using a minimum-mean square error short-time spectral amplitude estimator},
  author={Ephraim, Y. and Malah, D.},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing},
  volume={32},
  number={6},
  pages={1109--1121},
  year={1984},
  publisher={IEEE}
}


@INPROCEEDINGS{wei2016mmse,
  author={Wei, Jie and Wang, Ming and Yang, Hongxiao},
  booktitle={2016 IEEE International Conference on Digital Signal Processing (DSP)}, 
  title={MMSE-LSA based wavelet threshold denoising algorithm for low SNR speech}, 
  year={2016},
  volume={},
  number={},
  pages={253-256},
  keywords={Speech;Noise reduction;Signal to noise ratio;Speech enhancement;Noise measurement;Mathematical model;Information processing technology;Speech denoising;MMSE-LSA;Wavelet threshold;Low SNR},
  doi={10.1109/ICDSP.2016.7868556}
}


@inproceedings{sugahara2024hybrid,
  title={Hybrid Speech Enhancement for Hearing Aids with Deep Neural Networks and MMSE-LSA},
  author={Sugahara, Masataka and Kinoshita, Keisuke and Delcroix, Marc and Nakatani, Tomohiro},
  booktitle={ICASSP 2024 - IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2024},
  pages={701--705},
  publisher={IEEE},
  doi={10.1109/ICASSP48485.2024.10447335}
}

@misc{itutp862,
  title        = {{Perceptual Evaluation of Speech Quality (PESQ): An objective method for end-to-end speech quality assessment of narrow-band telephone networks and speech codecs}},
  author       = {{ITU-T Recommendation P.862}},
  year         = {2001},
  institution  = {International Telecommunication Union},
  howpublished = {\url{https://www.itu.int/rec/T-REC-P.862}},
  note         = {Accessed: 2025-04-19}
}

@inproceedings{taal2011stoi,
  author    = {Cees H. Taal and Richard C. Hendriks and Richard Heusdens and Jesper Jensen},
  title     = {An Algorithm for Intelligibility Prediction of Time–Frequency Weighted Noisy Speech},
  booktitle = {IEEE Transactions on Audio, Speech, and Language Processing},
  year      = {2011},
  volume    = {19},
  number    = {7},
  pages     = {2125--2136},
  doi       = {10.1109/TASL.2011.2114881}
}

@inproceedings{kubichek1993lsd,
  author    = {Robert Kubichek},
  title     = {Mel-Cepstral Distance Measure for Objective Speech Quality Assessment},
  booktitle = {IEEE Pacific Rim Conference on Communications, Computers and Signal Processing},
  year      = {1993},
  pages     = {125--128},
  doi       = {10.1109/PACRIM.1993.407206}
}

@misc{krisp2025,
  author       = {Krisp Technologies Inc.},
  title        = {Krisp: World's \#1 Noise Cancelling App and AI Meeting Assistant},
  howpublished = {\url{https://krisp.ai/}},
  year         = {2025}
}

@misc{nvidia2020,
  author       = {NVIDIA Corporation},
  title        = {NVIDIA RTX Voice: Setup Guide},
  howpublished = {\url{https://www.nvidia.com/en-us/geforce/guides/nvidia-rtx-voice-setup-guide/}},
  year         = {2020}
}

@misc{valin2018,
  author       = {Jean-Marc Valin},
  title        = {A Hybrid DSP/Deep Learning Approach to Real-Time Full-Band Speech Enhancement},
  howpublished = {\url{https://github.com/xiph/rnnoise}},
  year         = {2018}
}

@article{larcher2014text,
  title={Text-dependent speaker verification: Classifiers, databases and RSR2015},
  author={Larcher, Anthony and Lee, Kong Aik and Ma, Bin and Li, Haizhou},
  journal={Speech Communication},
  volume={60},
  pages={56--77},
  year={2014},
  publisher={Elsevier}
}

@article{azarang2020review,
  author    = {Arian Azarang and Nasser Kehtarnavaz},
  title     = {A review of multi-objective deep learning speech denoising methods},
  journal   = {Speech Communication},
  volume    = {122},
  pages     = {1--10},
  year      = {2020},
  issn      = {0167-6393},
  doi       = {10.1016/j.specom.2020.04.002},
  url       = {https://www.sciencedirect.com/science/article/pii/S0167639319304686},
  keywords  = {Speech denoising, Multi-objective deep learning, Denoising for speech recognition}
}

@inproceedings{vachhani2017dae,
  author    = {Vachhani, Bhavik and Bhat, Chitralekha and Das, Biswajit},
  title     = {Deep Autoencoder Based Speech Features for Improved Dysarthric Speech Recognition},
  booktitle = {Interspeech 2017},
  year      = {2017},
  doi       = {10.21437/Interspeech.2017-1318}
}

@misc{epoch2021,
  title={What’s the Backward-Forward FLOP Ratio for Neural Networks?},
  author={Marius Hobbhahn and Jaime Sevilla},
  year={2021},
  url={https://epoch.ai/blog/backward-forward-FLOP-ratio},
  note={Accessed: 2025-03-30}
}

@article{kim2024residual,
  author  = {Seon Kim},
  title   = {End‐to‐end speech‐denoising deep neural network based on residual‐attention gated linear units},
  journal = {Electronics Letters},
  volume  = {60},
  year    = {2024},
  doi     = {10.1049/ell2.70020}
}

@misc{edinburghdataset,
  author       = {Valentini-Botinhao, Cassia},
  title        = {Noisy Speech Database for Training Speech Enhancement Algorithms and TTS Models},
  year         = {2017},
  howpublished = {\url{https://datashare.ed.ac.uk/handle/10283/2791}},
  note         = {Accessed: 2025-03-23}
}

@misc{ccby4,
  author       = {{Creative Commons}},
  title        = {Attribution 4.0 International (CC BY 4.0)},
  year         = {2013},
  howpublished = {\url{https://creativecommons.org/licenses/by/4.0/legalcode}},
  note         = {Accessed: 2025-03-23}
}

@article{yoon2020pto,
  author  = {Sung-Hyun Yoon and Ha-Jin Yu},
  title   = {A Simple Distortion-Free Method to Handle Variable Length Sequences for Recurrent Neural Networks in Text Dependent Speaker Verification},
  journal = {Applied Sciences},
  volume  = {10},
  number  = {12},
  pages   = {4092},
  year    = {2020},
  issn    = {2076-3417},
  doi     = {10.3390/app10124092},
  url     = {https://www.mdpi.com/2076-3417/10/12/4092}
}

@misc{mindspore_mixed_precision,
  author       = {{MindSpore Contributors}},
  title        = {Mixed Precision Training — MindSpore Documentation},
  year         = {2024},
  url          = {https://www.mindspore.cn/tutorials/en/r2.3.0rc2/advanced/mixed_precision.html},
  note         = {Accessed: 2025-03-28}
}

@misc{chatgpt2025,
  author       = {OpenAI},
  title        = {ChatGPT Plus},
  note         = {\url{https://chat.openai.com}},
}

@misc{github_copilot,
  author       = {GitHub},
  title        = {GitHub Copilot},
  note         = {\url{https://github.com/features/copilot}},
}


@article{pesq_metric,
  author    = {A. W. Rix and J. G. Beerends and M. P. Hollier and A. P. Hekstra},
  title     = {Perceptual Evaluation of Speech Quality (PESQ)—A New Method for Speech Quality Assessment of Telephone Networks and Codecs},
  journal   = {IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)},
  year      = {2001},
  pages     = {749--752},
  doi       = {10.1109/ICASSP.2001.941023}
}


@inproceedings{park2017acoustic,
  title={A Fully Convolutional Neural Network for Speech Enhancement},
  author={Park, Se Rim and Lee, Jin Won},
  booktitle={Proceedings of the Annual Conference of the International Speech Communication Association (INTERSPEECH)},
  pages={1993--1997},
  year={2017},
  organization={ISCA},
  doi={10.21437/Interspeech.2017-1465}
}

@misc{ronneberger2015unet,
      title={U-Net: Convolutional Networks for Biomedical Image Segmentation}, 
      author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
      year={2015},
      eprint={1505.04597},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1505.04597}, 
}

@article{Luo2018ConvTasNetSI,
  title={Conv-TasNet: Surpassing Ideal Time–Frequency Magnitude Masking for Speech Separation},
  author={Yi Luo and Nima Mesgarani},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2018},
  volume={27},
  pages={1256-1266},
  url={https://api.semanticscholar.org/CorpusID:52310361}
}

@article{hu2007subjective,
  title={Subjective evaluation and comparison of speech enhancement algorithms},
  author={Hu, Yuantao and Loizou, Philipos C},
  journal={Speech Communication},
  volume={49},
  number={7-8},
  pages={588--601},
  year={2007},
  publisher={Elsevier},
  doi={10.1016/j.specom.2006.12.006}
}

@INPROCEEDINGS{wu2023scaleformer,
  author={Wu, Tianci and He, Shulin and Zhang, Hui and Zhang, XueLiang},
  booktitle={2023 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, 
  title={ScaleFormer: Transformer-based speech enhancement in the multi-scale time domain}, 
  year={2023},
  volume={},
  number={},
  pages={2448-2453},
  keywords={Measurement;Convolution;Neural networks;Transforms;Information processing;Speech enhancement;Transformers},
  doi={10.1109/APSIPAASC58517.2023.10317310}}

@inproceedings{defossez2019demucs,
  title     = {Music Source Separation in the Waveform Domain},
  author    = {Défossez, Alexandre and Usunier, Nicolas and Bottou, Léon and Bach, Francis},
  booktitle = {Proceedings of the International Society for Music Information Retrieval Conference (ISMIR)},
  year      = {2019},
  pages     = {754--760}
}

@article{li2022voicefixer,
  title   = {VoiceFixer: Toward General Speech Restoration with Neural Vocoder},
  author  = {Li, Xinhao and Liu, Qingju and Liu, Ziliang and Wang, Wenju and Wang, Lei Xie},
  journal = {IEEE Signal Processing Letters},
  volume  = {29},
  pages   = {1030--1034},
  year    = {2022},
  doi     = {10.1109/LSP.2022.3173732}
}

@inproceedings{meyer2022deepfilternet,
  title     = {DeepFilterNet: Towards Real-Time Speech Enhancement on Embedded Devices for Full-Band Audio},
  author    = {Meyer, Jan and Appeltans, David and Jalalvand, Azarakhsh and Van den Bogaert, Tim},
  booktitle = {Proc. Interspeech},
  pages     = {2673--2677},
  year      = {2022},
  doi       = {10.21437/Interspeech.2022-10711}
}
