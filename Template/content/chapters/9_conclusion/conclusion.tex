\chapter{Conclusion}
\label{chp:conclusion}

This project set out to explore and compare classical and \gls{ml} approaches for speech enhancement. A modular pipeline was implemented, supporting flexible experimentation through custom dataset loaders, real-time inference support, and unified evaluation metrics. Critical implementation flaws, such as the improper use of \texttt{Tanh} activations, were identified and resolved through iterative metric-based and visual analysis.

Evaluation began with classical methods: \gls{ss}, \gls{wf}, and \gls{mmse-lsa}, establishing a reliable performance baseline. The project then introduced and assessed five \gls{ml} models—\gls{cnn}, \gls{ced}, \gls{rced}, \gls{unet}, and \gls{convtasnet}. All trained from scratch in the spectrogram domain using the Edinburgh DataShare dataset \cite{edinburghdataset}. A key contribution was the design and evaluation of variable-length dataset handling strategies, including static and dynamic bucketing and padding-truncation approaches. These ensured efficient training across sequences of diverse lengths.

To address hardware limits, \gls{oom} mitigation strategies were implemented. While these slightly reduced training accuracy, they consistently improved denoising metrics and enabled deeper models like \gls{unet} and \gls{convtasnet} to be trained successfully. \gls{convtasnet} emerged as the top performer, achieving an \gls{snr} of 18.06~dB, \gls{pesq} of 2.43, and \gls{stoi} of 0.91. Although training was computationally intensive, with \gls{convtasnet} taking over 25 hours, these were one-time offline costs. Inference remained efficient, with the entire test set denoised in under two minutes. As summarised in Table~\ref{tab:summary_comparison}, this represents a substantial improvement over the best classical method, \gls{wf}, which achieved an \gls{snr} of 0.46~dB and \gls{pesq} of 2.06. The performance gap across all metrics highlights the clear advantage of data-driven \gls{ml} approaches in enhancing both numerical fidelity and perceptual quality, even when trained from scratch.

\vspace{1em}
\begin{table}[H]
\centering
\caption{Best Classical vs Best ML Denoising Performance}
\label{tab:summary_comparison}
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\textbf{Model} & \textbf{↑SNR (dB)} & \textbf{↓MSE} & \textbf{↑PESQ} & \textbf{↑STOI} & \textbf{↓LSD (dB)} \\
\hline
\gls{wf} (Best Classical) & 0.46 & 0.002875 & 2.06 & 0.89 & 0.75 \\
\gls{convtasnet} (Best ML) & 18.06 & 0.000063 & 2.43 & 0.91 & 0.67 \\
\hline
\end{tabular}
\end{table}
\vspace{1em}

In conclusion, this project demonstrated the viability of training speech enhancement models from scratch using a well-engineered system. The final pipeline supports robust evaluation and real-time denoising, validating \gls{ml}-based approaches as a practical and superior alternative to classical methods. This work lays the foundation for potential future developments discussed in Chapter~\ref{chp:future_work}.
